{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('nbagg')\n",
    "#from matplotlib import style\n",
    "#style.use('ggplot')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy import stats\n",
    "from astropy.io import fits\n",
    "from mmtwfs.wfs import *\n",
    "from mmtwfs.zernike import ZernikeVector\n",
    "from mmtwfs.telescope import MMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate all of the WFS systems...\n",
    "wfs_keys = ['newf9', 'f9', 'f5', 'mmirs']\n",
    "wfs_systems = {}\n",
    "wfs_names = {}\n",
    "for w in wfs_keys:\n",
    "    wfs_systems[w] = WFSFactory(wfs=w)\n",
    "    wfs_names[w] = wfs_systems[w].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_wfs(p):\n",
    "    \"\"\"\n",
    "    Check to see which system was used on a given night\n",
    "    \"\"\"\n",
    "    if Path.exists(p / \"F9\"):  # wow, i really like pathlib.Path...\n",
    "        return \"f9\"\n",
    "    elif Path.exists(p / \"F5\"):\n",
    "        return \"f5\"\n",
    "    elif Path.exists(p / \"MMIRS\"):\n",
    "        return 'mmirs'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def process_image(f):\n",
    "    \"\"\"\n",
    "    Process FITS file, f, to get info we want from the header and then analyse it with the \n",
    "    appropriate WFS instance. Return results in a comma-separated line that will be collected \n",
    "    and saved in a CSV file.\n",
    "    \"\"\"\n",
    "    if \"ave\" not in f.name:\n",
    "        with fits.open(f) as h:\n",
    "            hdr = h[0].header\n",
    "            if 'AIRMASS' in hdr:\n",
    "                airmass = hdr['AIRMASS']\n",
    "            else:\n",
    "                airmass = np.nan\n",
    "            # we need to fix the headers in all cases to have a proper DATE-OBS entry with\n",
    "            # properly formatted FITS timestamp.  in the meantime, this hack gets us what we need \n",
    "            # for analysis in pandas.\n",
    "            dateobs = hdr['DATEOBS']\n",
    "            ut = hdr['ut']\n",
    "            timestring = dateobs + \" \" + ut + \" UTC\"\n",
    "            dtime = datetime.strptime(timestring , \"%a %b %d %Y %H:%M:%S %Z\")\n",
    "            obstime = dtime.isoformat()\n",
    "            # being conservative here and only using data that has proper slope determination\n",
    "            # and wavefront solution. also want to get statistics on the quality of the wavefront fits.\n",
    "            results = wfs_systems[wfskey].measure_slopes(f, plot=False)\n",
    "            if results['slopes'] is not None:\n",
    "                zresults = wfs_systems[wfskey].fit_wavefront(results, plot=False)\n",
    "                line = \"%s,%s,%s,%f,%f,%f,%f,%f\\n\" % (\n",
    "                    obstime,\n",
    "                    wfskey,\n",
    "                    f.name, \n",
    "                    airmass,\n",
    "                    results['seeing'].value,\n",
    "                    results['raw_seeing'].value,\n",
    "                    results['fwhm'],\n",
    "                    zresults['residual_rms'].value\n",
    "                )\n",
    "                return line\n",
    "            else:\n",
    "                return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already processed 20170505...\n"
     ]
    }
   ],
   "source": [
    "rootdir = Path(\"/Users/tim/MMT/wfsdat/test\")\n",
    "dirs = rootdir.glob(\"*\")  # pathlib, where have you been all my life!\n",
    "csv_header = \"time,wfs,file,airmass,seeing,raw seeing,fwhm,wavefront rms\\n\"\n",
    "for d in dirs:\n",
    "    if d.is_dir():\n",
    "        if Path.exists(d / \"seeing_results.csv\"):\n",
    "            print(\"Already processed %s...\" % d.name)\n",
    "        else:\n",
    "            try:\n",
    "                lines = []\n",
    "                lines.append(csv_header)\n",
    "                night = int(d.name)  # valid WFS directories are ints of the form YYYYMMDD. if not this form, int barfs\n",
    "                msg = \"checking %d... \" % night\n",
    "                wfskey = check_wfs(d)\n",
    "                if wfskey is not None:\n",
    "                    if wfskey == \"mmirs\":\n",
    "                        rawd = d / \"rawdata\"\n",
    "                        fitsfiles = rawd.glob(\"*.fits\")\n",
    "                    else:\n",
    "                        fitsfiles = d.glob(\"*.fits\")\n",
    "                    if wfskey == \"f9\" and night > 20170510:\n",
    "                        wfskey = \"newf9\"\n",
    "                    msg += \" using %s.\" % wfskey\n",
    "                    print(msg)\n",
    "                    with Pool(processes=8) as pool:  # my mac's i7 has 4 cores + hyperthreading so 8 virtual cores. \n",
    "                        plines = pool.map(process_image, fitsfiles)  # plines comes out in same order as fitslines!\n",
    "                    plines = list(filter(None.__ne__, plines))  # trim out any None entries\n",
    "                    lines.extend(plines)\n",
    "                    with open(d / \"seeing_results.csv\", \"w\") as f:\n",
    "                        f.writelines(lines)\n",
    "                else:\n",
    "                    msg = \"No valid wfskey for %s...\" % d\n",
    "                    print(msg)\n",
    "            except ValueError:  # this means running int(d.name) failed so it's not a valid directory...\n",
    "                print(\"Skipping %s...\" % d.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = \"Thu May 18 2017\"\n",
    "datetime.strptime(t, \"%a %b %d %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"test.csv\", \"w\") as f:\n",
    "    f.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time, wfs, file, airmass, seeing, raw seeing, fwhm, wavefront rms\n",
      "2017-05-05T03:05:27, f5, auto_wfs_0000.fits, 1.330000, 1.088146, 1.291213, 8.005576, 1482.095233 \n",
      "2017-05-05T03:05:55, f5, auto_wfs_0001.fits, 1.330000, 1.013141, 1.202212, 7.581082, 1195.299068 \n",
      "2017-05-05T03:06:11, f5, auto_wfs_0002.fits, 1.330000, 0.968784, 1.149576, 7.328668, 1206.347418 \n",
      "2017-05-05T03:06:26, f5, auto_wfs_0003.fits, 1.330000, 0.861292, 1.022025, 6.712848, 1274.501378 \n",
      "2017-05-05T03:07:18, f5, auto_wfs_0004.fits, 1.320000, 0.865118, 1.021927, 6.712375, 1409.837661 \n",
      "2017-05-05T03:07:33, f5, auto_wfs_0005.fits, 1.320000, 0.872814, 1.031018, 6.756455, 1398.160690 \n",
      "2017-05-05T03:07:50, f5, auto_wfs_0006.fits, 1.320000, 1.114053, 1.315982, 8.123193, 1634.588775 \n",
      "2017-05-05T03:08:38, f5, auto_wfs_0007.fits, 1.320000, 0.998931, 1.179994, 7.474658, 266.336654 \n",
      "2017-05-05T03:08:54, f5, auto_wfs_0008.fits, 1.320000, 1.034293, 1.221765, 7.674592, 273.137820 \n",
      "2017-05-05T03:09:10, f5, auto_wfs_0009.fits, 1.310000, 1.169988, 1.375764, 8.406145, 303.806126 \n",
      "2017-05-05T03:09:55, f5, auto_wfs_0010.fits, 1.310000, 0.927808, 1.090991, 7.046534, 288.997787 \n",
      "\u001b[K\u001b[?1l\u001b>sv\u001b[m\u001b[K\u0007"
     ]
    }
   ],
   "source": [
    "!more test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/tim/MMT/wfsdat/test/20170505/seeing.csv')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d / \"seeing.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
